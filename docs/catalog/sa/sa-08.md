---
custom_edit_url: https://github.com/tamus-cyber/tamus-control-standards/tree/main/content/tamus.edu/TAMUS_profile.xml
toc_min_heading_level: 2
toc_max_heading_level: 2
title: SA-8 Security and Privacy Engineering Principles
description: ""
---

# SA-8 Security and Privacy Engineering Principles {#sa-08}

_**Implementation Level**_: Organization\
_**Contributes to Assurance**_: Yes\
_**Texas DIR Baseline**_: LOW\
_**Texas DIR Required By**_: 2023-07-20

### Control

Apply the following systems security and privacy engineering principles in the specification, design, development, implementation, and modification of the system and system components: <strong> <em>[Assignment: organization-defined systems security and privacy engineering principles]</em> </strong>.

<details>
  <summary>Supplemental Guidance</summary>

Systems security and privacy engineering principles are closely related to and implemented throughout the system development life cycle (see <a xmlns="http://csrc.nist.gov/ns/oscal/1.0" href="#sa-3">SA-3</a> ). Organizations can apply systems security and privacy engineering principles to new systems under development or to systems undergoing upgrades. For existing systems, organizations apply systems security and privacy engineering principles to system upgrades and modifications to the extent feasible, given the current state of hardware, software, and firmware components within those systems.

</details>

## SA-8(1) Clear Abstractions {#sa-08.01}

_**Implementation Level**_: Organization; Information System\
_**Contributes to Assurance**_: Yes

### Control

Implement the security design principle of clear abstractions.

<details>
  <summary>Supplemental Guidance</summary>

The principle of clear abstractions states that a system has simple, well-defined interfaces and functions that provide a consistent and intuitive view of the data and how the data is managed. The clarity, simplicity, necessity, and sufficiency of the system interfaces— combined with a precise definition of their functional behavior—promotes ease of analysis, inspection, and testing as well as the correct and secure use of the system. The clarity of an abstraction is subjective. Examples that reflect the application of this principle include avoidance of redundant, unused interfaces; information hiding; and avoidance of semantic overloading of interfaces or their parameters. Information hiding (i.e., representation-independent programming), is a design discipline used to ensure that the internal representation of information in one system component is not visible to another system component invoking or calling the first component, such that the published abstraction is not influenced by how the data may be managed internally.

</details>

## SA-8(2) Least Common Mechanism {#sa-08.02}

_**Implementation Level**_: Organization; Information System\
_**Contributes to Assurance**_: Yes

### Control

Implement the security design principle of least common mechanism in <strong> <em>[Assignment: systems or system components]</em> </strong>.

<details>
  <summary>Supplemental Guidance</summary>

The principle of least common mechanism states that the amount of mechanism common to more than one user and depended on by all users is minimized <a xmlns="http://csrc.nist.gov/ns/oscal/1.0" href="#79453f84-26a4-4995-8257-d32d37aefea3">POPEK74</a> . Mechanism minimization implies that different components of a system refrain from using the same mechanism to access a system resource. Every shared mechanism (especially a mechanism involving shared variables) represents a potential information path between users and is designed with care to ensure that it does not unintentionally compromise security <a xmlns="http://csrc.nist.gov/ns/oscal/1.0" href="#c9495d6e-ef64-4090-8509-e58c3b9009ff">SALTZER75</a> . Implementing the principle of least common mechanism helps to reduce the adverse consequences of sharing the system state among different programs. A single program that corrupts a shared state (including shared variables) has the potential to corrupt other programs that are dependent on the state. The principle of least common mechanism also supports the principle of simplicity of design and addresses the issue of covert storage channels <a xmlns="http://csrc.nist.gov/ns/oscal/1.0" href="#d1cdab13-4218-400d-91a9-c3818dfa5ec8">LAMPSON73</a>.

</details>

## SA-8(3) Modularity and Layering {#sa-08.03}

_**Implementation Level**_: Organization; Information System\
_**Contributes to Assurance**_: Yes

### Control

Implement the security design principles of modularity and layering in <strong> <em>[Assignment: organization-defined systems or system components]</em> </strong>.

<details>
  <summary>Supplemental Guidance</summary>

The principles of modularity and layering are fundamental across system engineering disciplines. Modularity and layering derived from functional decomposition are effective in managing system complexity by making it possible to comprehend the structure of the system. Modular decomposition, or refinement in system design, is challenging and resists general statements of principle. Modularity serves to isolate functions and related data structures into well-defined logical units. Layering allows the relationships of these units to be better understood so that dependencies are clear and undesired complexity can be avoided. The security design principle of modularity extends functional modularity to include considerations based on trust, trustworthiness, privilege, and security policy. Security-informed modular decomposition includes the allocation of policies to systems in a network, separation of system applications into processes with distinct address spaces, allocation of system policies to layers, and separation of processes into subjects with distinct privileges based on hardware-supported privilege domains.

</details>

## SA-8(4) Partially Ordered Dependencies {#sa-08.04}

_**Implementation Level**_: Organization; Information System\
_**Contributes to Assurance**_: Yes

### Control

Implement the security design principle of partially ordered dependencies in <strong> <em>[Assignment: systems or system components]</em> </strong>.

<details>
  <summary>Supplemental Guidance</summary>

The principle of partially ordered dependencies states that the synchronization, calling, and other dependencies in the system are partially ordered. A fundamental concept in system design is layering, whereby the system is organized into well-defined, functionally related modules or components. The layers are linearly ordered with respect to inter-layer dependencies, such that higher layers are dependent on lower layers. While providing functionality to higher layers, some layers can be self-contained and not dependent on lower layers. While a partial ordering of all functions in a given system may not be possible, if circular dependencies are constrained to occur within layers, the inherent problems of circularity can be more easily managed. Partially ordered dependencies and system layering contribute significantly to the simplicity and coherency of the system design. Partially ordered dependencies also facilitate system testing and analysis.

</details>

## SA-8(5) Efficiently Mediated Access {#sa-08.05}

_**Implementation Level**_: Organization; Information System\
_**Contributes to Assurance**_: Yes

### Control

Implement the security design principle of efficiently mediated access in <strong> <em>[Assignment: systems or system components]</em> </strong>.

<details>
  <summary>Supplemental Guidance</summary>

The principle of efficiently mediated access states that policy enforcement mechanisms utilize the least common mechanism available while satisfying stakeholder requirements within expressed constraints. The mediation of access to system resources (i.e., CPU, memory, devices, communication ports, services, infrastructure, data, and information) is often the predominant security function of secure systems. It also enables the realization of protections for the capability provided to stakeholders by the system. Mediation of resource access can result in performance bottlenecks if the system is not designed correctly. For example, by using hardware mechanisms, efficiently mediated access can be achieved. Once access to a low-level resource such as memory has been obtained, hardware protection mechanisms can ensure that out-of-bounds access does not occur.

</details>

## SA-8(6) Minimized Sharing {#sa-08.06}

_**Implementation Level**_: Organization; Information System\
_**Contributes to Assurance**_: Yes

### Control

Implement the security design principle of minimized sharing in <strong> <em>[Assignment: systems or system components]</em> </strong>.

<details>
  <summary>Supplemental Guidance</summary>

The principle of minimized sharing states that no computer resource is shared between system components (e.g., subjects, processes, functions) unless it is absolutely necessary to do so. Minimized sharing helps to simplify system design and implementation. In order to protect user-domain resources from arbitrary active entities, no resource is shared unless that sharing has been explicitly requested and granted. The need for resource sharing can be motivated by the design principle of least common mechanism in the case of internal entities or driven by stakeholder requirements. However, internal sharing is carefully designed to avoid performance and covert storage and timing channel problems. Sharing via common mechanism can increase the susceptibility of data and information to unauthorized access, disclosure, use, or modification and can adversely affect the inherent capability provided by the system. To minimize sharing induced by common mechanisms, such mechanisms can be designed to be reentrant or virtualized to preserve separation. Moreover, the use of global data to share information is carefully scrutinized. The lack of encapsulation may obfuscate relationships among the sharing entities.

</details>

## SA-8(7) Reduced Complexity {#sa-08.07}

_**Implementation Level**_: Organization; Information System\
_**Contributes to Assurance**_: Yes

### Control

Implement the security design principle of reduced complexity in <strong> <em>[Assignment: systems or system components]</em> </strong>.

<details>
  <summary>Supplemental Guidance</summary>

The principle of reduced complexity states that the system design is as simple and small as possible. A small and simple design is more understandable, more analyzable, and less prone to error. The reduced complexity principle applies to any aspect of a system, but it has particular importance for security due to the various analyses performed to obtain evidence about the emergent security property of the system. For such analyses to be successful, a small and simple design is essential. Application of the principle of reduced complexity contributes to the ability of system developers to understand the correctness and completeness of system security functions. It also facilitates the identification of potential vulnerabilities. The corollary of reduced complexity states that the simplicity of the system is directly related to the number of vulnerabilities it will contain; that is, simpler systems contain fewer vulnerabilities. An benefit of reduced complexity is that it is easier to understand whether the intended security policy has been captured in the system design and that fewer vulnerabilities are likely to be introduced during engineering development. An additional benefit is that any such conclusion about correctness, completeness, and the existence of vulnerabilities can be reached with a higher degree of assurance in contrast to conclusions reached in situations where the system design is inherently more complex. Transitioning from older technologies to newer technologies (e.g., transitioning from IPv4 to IPv6) may require implementing the older and newer technologies simultaneously during the transition period. This may result in a temporary increase in system complexity during the transition.

</details>

## SA-8(8) Secure Evolvability {#sa-08.08}

_**Implementation Level**_: Organization; Information System\
_**Contributes to Assurance**_: Yes

### Control

Implement the security design principle of secure evolvability in <strong> <em>[Assignment: systems or system components]</em> </strong>.

<details>
  <summary>Supplemental Guidance</summary>

The principle of secure evolvability states that a system is developed to facilitate the maintenance of its security properties when there are changes to the system’s structure, interfaces, interconnections (i.e., system architecture), functionality, or configuration (i.e., security policy enforcement). Changes include a new, enhanced, or upgraded system capability; maintenance and sustainment activities; and reconfiguration. Although it is not possible to plan for every aspect of system evolution, system upgrades and changes can be anticipated by analyses of mission or business strategic direction, anticipated changes in the threat environment, and anticipated maintenance and sustainment needs. It is unrealistic to expect that complex systems remain secure in contexts not envisioned during development, whether such contexts are related to the operational environment or to usage. A system may be secure in some new contexts, but there is no guarantee that its emergent behavior will always be secure. It is easier to build trustworthiness into a system from the outset, and it follows that the sustainment of system trustworthiness requires planning for change as opposed to adapting in an ad hoc or non-methodical manner. The benefits of this principle include reduced vendor life cycle costs, reduced cost of ownership, improved system security, more effective management of security risk, and less risk uncertainty.

</details>

## SA-8(9) Trusted Components {#sa-08.09}

_**Implementation Level**_: Organization; Information System\
_**Contributes to Assurance**_: Yes

### Control

Implement the security design principle of trusted components in <strong> <em>[Assignment: systems or system components]</em> </strong>.

<details>
  <summary>Supplemental Guidance</summary>

The principle of trusted components states that a component is trustworthy to at least a level commensurate with the security dependencies it supports (i.e., how much it is trusted to perform its security functions by other components). This principle enables the composition of components such that trustworthiness is not inadvertently diminished and the trust is not consequently misplaced. Ultimately, this principle demands some metric by which the trust in a component and the trustworthiness of a component can be measured on the same abstract scale. The principle of trusted components is particularly relevant when considering systems and components in which there are complex chains of trust dependencies. A trust dependency is also referred to as a trust relationship and there may be chains of trust relationships.

</details>

## SA-8(10) Hierarchical Trust {#sa-08.10}

_**Implementation Level**_: Organization; Information System\
_**Contributes to Assurance**_: Yes

### Control

Implement the security design principle of hierarchical trust in <strong> <em>[Assignment: systems or system components]</em> </strong>.

<details>
  <summary>Supplemental Guidance</summary>

The principle of hierarchical trust for components builds on the principle of trusted components and states that the security dependencies in a system will form a partial ordering if they preserve the principle of trusted components. The partial ordering provides the basis for trustworthiness reasoning or an assurance case (assurance argument) when composing a secure system from heterogeneously trustworthy components. To analyze a system composed of heterogeneously trustworthy components for its trustworthiness, it is essential to eliminate circular dependencies with regard to the trustworthiness. If a more trustworthy component located in a lower layer of the system were to depend on a less trustworthy component in a higher layer, this would, in effect, put the components in the same <q xmlns="http://csrc.nist.gov/ns/oscal/1.0">less trustworthy</q> equivalence class per the principle of trusted components. Trust relationships, or chains of trust, can have various manifestations. For example, the root certificate of a certificate hierarchy is the most trusted node in the hierarchy, whereas the leaves in the hierarchy may be the least trustworthy nodes. Another example occurs in a layered high-assurance system where the security kernel (including the hardware base), which is located at the lowest layer of the system, is the most trustworthy component. The principle of hierarchical trust, however, does not prohibit the use of overly trustworthy components. There may be cases in a system of low trustworthiness where it is reasonable to employ a highly trustworthy component rather than one that is less trustworthy (e.g., due to availability or other cost-benefit driver). For such a case, any dependency of the highly trustworthy component upon a less trustworthy component does not degrade the trustworthiness of the resulting low-trust system.

</details>

## SA-8(11) Inverse Modification Threshold {#sa-08.11}

_**Implementation Level**_: Organization; Information System\
_**Contributes to Assurance**_: Yes

### Control

Implement the security design principle of inverse modification threshold in <strong> <em>[Assignment: systems or system components]</em> </strong>.

<details>
  <summary>Supplemental Guidance</summary>

The principle of inverse modification threshold builds on the principle of trusted components and the principle of hierarchical trust and states that the degree of protection provided to a component is commensurate with its trustworthiness. As the trust placed in a component increases, the protection against unauthorized modification of the component also increases to the same degree. Protection from unauthorized modification can come in the form of the component’s own self-protection and innate trustworthiness, or it can come from the protections afforded to the component from other elements or attributes of the security architecture (to include protections in the environment of operation).

</details>

## SA-8(12) Hierarchical Protection {#sa-08.12}

_**Implementation Level**_: Organization; Information System\
_**Contributes to Assurance**_: Yes

### Control

Implement the security design principle of hierarchical protection in <strong> <em>[Assignment: systems or system components]</em> </strong>.

<details>
  <summary>Supplemental Guidance</summary>

The principle of hierarchical protection states that a component need not be protected from more trustworthy components. In the degenerate case of the most trusted component, it protects itself from all other components. For example, if an operating system kernel is deemed the most trustworthy component in a system, then it protects itself from all untrusted applications it supports, but the applications, conversely, do not need to protect themselves from the kernel. The trustworthiness of users is a consideration for applying the principle of hierarchical protection. A trusted system need not protect itself from an equally trustworthy user, reflecting use of untrusted systems in <q xmlns="http://csrc.nist.gov/ns/oscal/1.0">system high</q> environments where users are highly trustworthy and where other protections are put in place to bound and protect the <q xmlns="http://csrc.nist.gov/ns/oscal/1.0">system high</q> execution environment.

</details>

## SA-8(13) Minimized Security Elements {#sa-08.13}

_**Implementation Level**_: Organization; Information System\
_**Contributes to Assurance**_: Yes

### Control

Implement the security design principle of minimized security elements in <strong> <em>[Assignment: systems or system components]</em> </strong>.

<details>
  <summary>Supplemental Guidance</summary>

The principle of minimized security elements states that the system does not have extraneous trusted components. The principle of minimized security elements has two aspects: the overall cost of security analysis and the complexity of security analysis. Trusted components are generally costlier to construct and implement, owing to the increased rigor of development processes. Trusted components require greater security analysis to qualify their trustworthiness. Thus, to reduce the cost and decrease the complexity of the security analysis, a system contains as few trustworthy components as possible. The analysis of the interaction of trusted components with other components of the system is one of the most important aspects of system security verification. If the interactions between components are unnecessarily complex, the security of the system will also be more difficult to ascertain than one whose internal trust relationships are simple and elegantly constructed. In general, fewer trusted components result in fewer internal trust relationships and a simpler system.

</details>

## SA-8(14) Least Privilege {#sa-08.14}

_**Implementation Level**_: Organization; Information System\
_**Contributes to Assurance**_: Yes

### Control

Implement the security design principle of least privilege in <strong> <em>[Assignment: systems or system components]</em> </strong>.

<details>
  <summary>Supplemental Guidance</summary>

The principle of least privilege states that each system component is allocated sufficient privileges to accomplish its specified functions but no more. Applying the principle of least privilege limits the scope of the component’s actions, which has two desirable effects: the security impact of a failure, corruption, or misuse of the component will have a minimized security impact, and the security analysis of the component will be simplified. Least privilege is a pervasive principle that is reflected in all aspects of the secure system design. Interfaces used to invoke component capability are available to only certain subsets of the user population, and component design supports a sufficiently fine granularity of privilege decomposition. For example, in the case of an audit mechanism, there may be an interface for the audit manager, who configures the audit settings; an interface for the audit operator, who ensures that audit data is safely collected and stored; and, finally, yet another interface for the audit reviewer, who only has need to view the audit data that has been collected but no need to perform operations on that data.

</details>

## SA-8(15) Predicate Permission {#sa-08.15}

_**Implementation Level**_: Organization; Information System\
_**Contributes to Assurance**_: Yes

### Control

Implement the security design principle of predicate permission in <strong> <em>[Assignment: systems or system components]</em> </strong>.

<details>
  <summary>Supplemental Guidance</summary>

The principle of predicate permission states that system designers consider requiring multiple authorized entities to provide consent before a highly critical operation or access to highly sensitive data, information, or resources is allowed to proceed. <a xmlns="http://csrc.nist.gov/ns/oscal/1.0" href="#c9495d6e-ef64-4090-8509-e58c3b9009ff">SALTZER75</a> originally named predicate permission the separation of privilege. It is also equivalent to separation of duty. The division of privilege among multiple parties decreases the likelihood of abuse and provides the safeguard that no single accident, deception, or breach of trust is sufficient to enable an unrecoverable action that can lead to significantly damaging effects. The design options for such a mechanism may require simultaneous action (e.g., the firing of a nuclear weapon requires two different authorized individuals to give the correct command within a small time window) or a sequence of operations where each successive action is enabled by some prior action, but no single individual is able to enable more than one action.

</details>

## SA-8(16) Self-reliant Trustworthiness {#sa-08.16}

_**Implementation Level**_: Organization; Information System\
_**Contributes to Assurance**_: Yes

### Control

Implement the security design principle of self-reliant trustworthiness in <strong> <em>[Assignment: systems or system components]</em> </strong>.

<details>
  <summary>Supplemental Guidance</summary>

The principle of self-reliant trustworthiness states that systems minimize their reliance on other systems for their own trustworthiness. A system is trustworthy by default, and any connection to an external entity is used to supplement its function. If a system were required to maintain a connection with another external entity in order to maintain its trustworthiness, then that system would be vulnerable to malicious and non-malicious threats that could result in the loss or degradation of that connection. The benefit of the principle of self-reliant trustworthiness is that the isolation of a system will make it less vulnerable to attack. A corollary to this principle relates to the ability of the system (or system component) to operate in isolation and then resynchronize with other components when it is rejoined with them.

</details>

## SA-8(17) Secure Distributed Composition {#sa-08.17}

_**Implementation Level**_: Organization; Information System\
_**Contributes to Assurance**_: Yes

### Control

Implement the security design principle of secure distributed composition in <strong> <em>[Assignment: systems or system components]</em> </strong>.

<details>
  <summary>Supplemental Guidance</summary>

The principle of secure distributed composition states that the composition of distributed components that enforce the same system security policy result in a system that enforces that policy at least as well as the individual components do. Many of the design principles for secure systems deal with how components can or should interact. The need to create or enable a capability from the composition of distributed components can magnify the relevancy of these principles. In particular, the translation of security policy from a stand-alone to a distributed system or a system-of-systems can have unexpected or emergent results. Communication protocols and distributed data consistency mechanisms help to ensure consistent policy enforcement across a distributed system. To ensure a system-wide level of assurance of correct policy enforcement, the security architecture of a distributed composite system is thoroughly analyzed.

</details>

## SA-8(18) Trusted Communications Channels {#sa-08.18}

_**Implementation Level**_: Organization; Information System\
_**Contributes to Assurance**_: Yes

### Control

Implement the security design principle of trusted communications channels in <strong> <em>[Assignment: systems or system components]</em> </strong>.

<details>
  <summary>Supplemental Guidance</summary>

The principle of trusted communication channels states that when composing a system where there is a potential threat to communications between components (i.e., the interconnections between components), each communication channel is trustworthy to a level commensurate with the security dependencies it supports (i.e., how much it is trusted by other components to perform its security functions). Trusted communication channels are achieved by a combination of restricting access to the communication channel (to ensure an acceptable match in the trustworthiness of the endpoints involved in the communication) and employing end-to-end protections for the data transmitted over the communication channel (to protect against interception and modification and to further increase the assurance of proper end-to-end communication).

</details>

## SA-8(19) Continuous Protection {#sa-08.19}

_**Implementation Level**_: Organization; Information System\
_**Contributes to Assurance**_: Yes

### Control

Implement the security design principle of continuous protection in <strong> <em>[Assignment: systems or system components]</em> </strong>.

<details>
  <summary>Supplemental Guidance</summary>

The principle of continuous protection states that components and data used to enforce the security policy have uninterrupted protection that is consistent with the security policy and the security architecture assumptions. No assurances that the system can provide the confidentiality, integrity, availability, and privacy protections for its design capability can be made if there are gaps in the protection. Any assurances about the ability to secure a delivered capability require that data and information are continuously protected. That is, there are no periods during which data and information are left unprotected while under control of the system (i.e., during the creation, storage, processing, or communication of the data and information, as well as during system initialization, execution, failure, interruption, and shutdown). Continuous protection requires adherence to the precepts of the reference monitor concept (i.e., every request is validated by the reference monitor; the reference monitor is able to protect itself from tampering; and sufficient assurance of the correctness and completeness of the mechanism can be ascertained from analysis and testing) and the principle of secure failure and recovery (i.e., preservation of a secure state during error, fault, failure, and successful attack; preservation of a secure state during recovery to normal, degraded, or alternative operational modes).

</details>

## SA-8(20) Secure Metadata Management {#sa-08.20}

_**Implementation Level**_: Organization; Information System\
_**Contributes to Assurance**_: Yes

### Control

Implement the security design principle of secure metadata management in <strong> <em>[Assignment: systems or system components]</em> </strong>.

<details>
  <summary>Supplemental Guidance</summary>

The principle of secure metadata management states that metadata are <q xmlns="http://csrc.nist.gov/ns/oscal/1.0">first class</q> objects with respect to security policy when the policy requires either complete protection of information or that the security subsystem be self-protecting. The principle of secure metadata management is driven by the recognition that a system, subsystem, or component cannot achieve self-protection unless it protects the data it relies on for correct execution. Data is generally not interpreted by the system that stores it. It may have semantic value (i.e., it comprises information) to users and programs that process the data. In contrast, metadata is information about data, such as a file name or the date when the file was created. Metadata is bound to the target data that it describes in a way that the system can interpret, but it need not be stored inside of or proximate to its target data. There may be metadata whose target is itself metadata (e.g., the classification level or impact level of a file name), including self-referential metadata.

</details>

## SA-8(21) Self-analysis {#sa-08.21}

_**Implementation Level**_: Organization; Information System\
_**Contributes to Assurance**_: Yes

### Control

Implement the security design principle of self-analysis in <strong> <em>[Assignment: systems or system components]</em> </strong>.

<details>
  <summary>Supplemental Guidance</summary>

The principle of self-analysis states that a system component is able to assess its internal state and functionality to a limited extent at various stages of execution, and that this self-analysis capability is commensurate with the level of trustworthiness invested in the system. At the system level, self-analysis can be achieved through hierarchical assessments of trustworthiness established in a bottom-up fashion. In this approach, the lower-level components check for data integrity and correct functionality (to a limited extent) of higher-level components. For example, trusted boot sequences involve a trusted lower-level component that attests to the trustworthiness of the next higher-level components so that a transitive chain of trust can be established. At the root, a component attests to itself, which usually involves an axiomatic or environmentally enforced assumption about its integrity. Results of the self-analyses can be used to guard against externally induced errors, internal malfunction, or transient errors. By following this principle, some simple malfunctions or errors can be detected without allowing the effects of the error or malfunction to propagate outside of the component. Further, the self-test can be used to attest to the configuration of the component, detecting any potential conflicts in configuration with respect to the expected configuration.

</details>

## SA-8(22) Accountability and Traceability {#sa-08.22}

_**Implementation Level**_: Organization; Information System\
_**Contributes to Assurance**_: Yes

### Control

Implement the security design principle of accountability and traceability in <strong> <em>[Assignment: organization-defined systems or system components]</em> </strong>.

<details>
  <summary>Supplemental Guidance</summary>

The principle of accountability and traceability states that it is possible to trace security-relevant actions (i.e., subject-object interactions) to the entity on whose behalf the action is being taken. The principle of accountability and traceability requires a trustworthy infrastructure that can record details about actions that affect system security (e.g., an audit subsystem). To record the details about actions, the system is able to uniquely identify the entity on whose behalf the action is being carried out and also record the relevant sequence of actions that are carried out. The accountability policy also requires that audit trail itself be protected from unauthorized access and modification. The principle of least privilege assists in tracing the actions to particular entities, as it increases the granularity of accountability. Associating specific actions with system entities, and ultimately with users, and making the audit trail secure against unauthorized access and modifications provide non-repudiation because once an action is recorded, it is not possible to change the audit trail. Another important function that accountability and traceability serves is in the routine and forensic analysis of events associated with the violation of security policy. Analysis of audit logs may provide additional information that may be helpful in determining the path or component that allowed the violation of the security policy and the actions of individuals associated with the violation of the security policy.

</details>

## SA-8(23) Secure Defaults {#sa-08.23}

_**Implementation Level**_: Organization; Information System\
_**Contributes to Assurance**_: Yes

### Control

Implement the security design principle of secure defaults in <strong> <em>[Assignment: systems or system components]</em> </strong>.

<details>
  <summary>Supplemental Guidance</summary>

The principle of secure defaults states that the default configuration of a system (including its constituent subsystems, components, and mechanisms) reflects a restrictive and conservative enforcement of security policy. The principle of secure defaults applies to the initial (i.e., default) configuration of a system as well as to the security engineering and design of access control and other security functions that follow a <q xmlns="http://csrc.nist.gov/ns/oscal/1.0">deny unless explicitly authorized</q> strategy. The initial configuration aspect of this principle requires that any <q xmlns="http://csrc.nist.gov/ns/oscal/1.0">as shipped</q> configuration of a system, subsystem, or system component does not aid in the violation of the security policy and can prevent the system from operating in the default configuration for those cases where the security policy itself requires configuration by the operational user.

</details>

## SA-8(24) Secure Failure and Recovery {#sa-08.24}

_**Implementation Level**_: Organization; Information System\
_**Contributes to Assurance**_: Yes

### Control

Implement the security design principle of secure failure and recovery in <strong> <em>[Assignment: organization-defined systems or system components]</em> </strong>.

<details>
  <summary>Supplemental Guidance</summary>

The principle of secure failure and recovery states that neither a failure in a system function or mechanism nor any recovery action in response to failure leads to a violation of security policy. The principle of secure failure and recovery parallels the principle of continuous protection to ensure that a system is capable of detecting (within limits) actual and impending failure at any stage of its operation (i.e., initialization, normal operation, shutdown, and maintenance) and to take appropriate steps to ensure that security policies are not violated. In addition, when specified, the system is capable of recovering from impending or actual failure to resume normal, degraded, or alternative secure operations while ensuring that a secure state is maintained such that security policies are not violated.

</details>

## SA-8(25) Economic Security {#sa-08.25}

_**Implementation Level**_: Organization; Information System\
_**Contributes to Assurance**_: Yes

### Control

Implement the security design principle of economic security in <strong> <em>[Assignment: systems or system components]</em> </strong>.

<details>
  <summary>Supplemental Guidance</summary>

The principle of economic security states that security mechanisms are not costlier than the potential damage that could occur from a security breach. This is the security-relevant form of the cost-benefit analyses used in risk management. The cost assumptions of cost-benefit analysis prevent the system designer from incorporating security mechanisms of greater strength than necessary, where strength of mechanism is proportional to cost. The principle of economic security also requires analysis of the benefits of assurance relative to the cost of that assurance in terms of the effort expended to obtain relevant and credible evidence as well as the necessary analyses to assess and draw trustworthiness and risk conclusions from the evidence.

</details>

## SA-8(26) Performance Security {#sa-08.26}

_**Implementation Level**_: Organization; Information System\
_**Contributes to Assurance**_: Yes

### Control

Implement the security design principle of performance security in <strong> <em>[Assignment: systems or system components]</em> </strong>.

<details>
  <summary>Supplemental Guidance</summary>

The principle of performance security states that security mechanisms are constructed so that they do not degrade system performance unnecessarily. Stakeholder and system design requirements for performance and security are precisely articulated and prioritized. For the system implementation to meet its design requirements and be found acceptable to stakeholders (i.e., validation against stakeholder requirements), the designers adhere to the specified constraints that capability performance needs place on protection needs. The overall impact of computationally intensive security services (e.g., cryptography) are assessed and demonstrated to pose no significant impact to higher-priority performance considerations or are deemed to provide an acceptable trade-off of performance for trustworthy protection. The trade-off considerations include less computationally intensive security services unless they are unavailable or insufficient. The insufficiency of a security service is determined by functional capability and strength of mechanism. The strength of mechanism is selected with respect to security requirements, performance-critical overhead issues (e.g., cryptographic key management), and an assessment of the capability of the threat.

</details>

## SA-8(27) Human Factored Security {#sa-08.27}

_**Implementation Level**_: Organization; Information System\
_**Contributes to Assurance**_: Yes

### Control

Implement the security design principle of human factored security in <strong> <em>[Assignment: systems or system components]</em> </strong>.

<details>
  <summary>Supplemental Guidance</summary>

The principle of human factored security states that the user interface for security functions and supporting services is intuitive, user-friendly, and provides feedback for user actions that affect such policy and its enforcement. The mechanisms that enforce security policy are not intrusive to the user and are designed not to degrade user efficiency. Security policy enforcement mechanisms also provide the user with meaningful, clear, and relevant feedback and warnings when insecure choices are being made. Particular attention is given to interfaces through which personnel responsible for system administration and operation configure and set up the security policies. Ideally, these personnel are able to understand the impact of their choices. Personnel with system administrative and operational responsibilities are able to configure systems before start-up and administer them during runtime with confidence that their intent is correctly mapped to the system’s mechanisms. Security services, functions, and mechanisms do not impede or unnecessarily complicate the intended use of the system. There is a trade-off between system usability and the strictness necessary for security policy enforcement. If security mechanisms are frustrating or difficult to use, then users may disable them, avoid them, or use them in ways inconsistent with the security requirements and protection needs that the mechanisms were designed to satisfy.

</details>

## SA-8(28) Acceptable Security {#sa-08.28}

_**Implementation Level**_: Organization; Information System\
_**Contributes to Assurance**_: Yes

### Control

Implement the security design principle of acceptable security in <strong> <em>[Assignment: systems or system components]</em> </strong>.

<details>
  <summary>Supplemental Guidance</summary>

The principle of acceptable security requires that the level of privacy and performance that the system provides is consistent with the users’ expectations. The perception of personal privacy may affect user behavior, morale, and effectiveness. Based on the organizational privacy policy and the system design, users should be able to restrict their actions to protect their privacy. When systems fail to provide intuitive interfaces or meet privacy and performance expectations, users may either choose to completely avoid the system or use it in ways that may be inefficient or even insecure.

</details>

## SA-8(29) Repeatable and Documented Procedures {#sa-08.29}

_**Implementation Level**_: Organization; Information System\
_**Contributes to Assurance**_: Yes

### Control

Implement the security design principle of repeatable and documented procedures in <strong> <em>[Assignment: systems or system components]</em> </strong>.

<details>
  <summary>Supplemental Guidance</summary>

The principle of repeatable and documented procedures states that the techniques and methods employed to construct a system component permit the same component to be completely and correctly reconstructed at a later time. Repeatable and documented procedures support the development of a component that is identical to the component created earlier, which may be in widespread use. In the case of other system artifacts (e.g., documentation and testing results), repeatability supports consistency and the ability to inspect the artifacts. Repeatable and documented procedures can be introduced at various stages within the system development life cycle and contribute to the ability to evaluate assurance claims for the system. Examples include systematic procedures for code development and review, procedures for the configuration management of development tools and system artifacts, and procedures for system delivery.

</details>

## SA-8(30) Procedural Rigor {#sa-08.30}

_**Implementation Level**_: Organization; Information System\
_**Contributes to Assurance**_: Yes

### Control

Implement the security design principle of procedural rigor in <strong> <em>[Assignment: systems or system components]</em> </strong>.

<details>
  <summary>Supplemental Guidance</summary>

The principle of procedural rigor states that the rigor of a system life cycle process is commensurate with its intended trustworthiness. Procedural rigor defines the scope, depth, and detail of the system life cycle procedures. Rigorous system life cycle procedures contribute to the assurance that the system is correct and free of unintended functionality in several ways. First, the procedures impose checks and balances on the life cycle process such that the introduction of unspecified functionality is prevented.

</details>

## SA-8(31) Secure System Modification {#sa-08.31}

_**Implementation Level**_: Organization; Information System\
_**Contributes to Assurance**_: Yes

### Control

Implement the security design principle of secure system modification in <strong> <em>[Assignment: systems or system components]</em> </strong>.

<details>
  <summary>Supplemental Guidance</summary>

The principle of secure system modification states that system modification maintains system security with respect to the security requirements and risk tolerance of stakeholders. Upgrades or modifications to systems can transform secure systems into systems that are not secure. The procedures for system modification ensure that if the system is to maintain its trustworthiness, the same rigor that was applied to its initial development is applied to any system changes. Because modifications can affect the ability of the system to maintain its secure state, a careful security analysis of the modification is needed prior to its implementation and deployment. This principle parallels the principle of secure evolvability.

</details>

## SA-8(32) Sufficient Documentation {#sa-08.32}

_**Implementation Level**_: Organization; Information System\
_**Contributes to Assurance**_: Yes

### Control

Implement the security design principle of sufficient documentation in <strong> <em>[Assignment: systems or system components]</em> </strong>.

<details>
  <summary>Supplemental Guidance</summary>

The principle of sufficient documentation states that organizational personnel with responsibilities to interact with the system are provided with adequate documentation and other information such that the personnel contribute to rather than detract from system security. Despite attempts to comply with principles such as human factored security and acceptable security, systems are inherently complex, and the design intent for the use of security mechanisms and the ramifications of the misuse or misconfiguration of security mechanisms are not always intuitively obvious. Uninformed and insufficiently trained users can introduce vulnerabilities due to errors of omission and commission. The availability of documentation and training can help to ensure a knowledgeable cadre of personnel, all of whom have a critical role in the achievement of principles such as continuous protection. Documentation is written clearly and supported by training that provides security awareness and understanding of security-relevant responsibilities.

</details>

## SA-8(33) Minimization {#sa-08.33}

_**Implementation Level**_: Organization; Information System\
_**Contributes to Assurance**_: Yes

### Control

Implement the privacy principle of minimization using <strong> <em>[Assignment: processes]</em> </strong>.

<details>
  <summary>Supplemental Guidance</summary>

The principle of minimization states that organizations should only process personally identifiable information that is directly relevant and necessary to accomplish an authorized purpose and should only maintain personally identifiable information for as long as is necessary to accomplish the purpose. Organizations have processes in place, consistent with applicable laws and policies, to implement the principle of minimization.

</details>

